{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b068f73",
   "metadata": {},
   "source": [
    "Note: \\\n",
    "It might be much faster using asynchronous programming and parsel: import asyncio, import aiohttp, from parsel import Selector, lxml was faster too \\\n",
    "Asyncio with Multiprocessing do this for faster return time for later use \\\n",
    "Even merged parallel (right after a df is returned) instead of merging one of byafter we get all the dataframe at the end \\\n",
    "\n",
    "checkout for race condition (is there any race conditon? the shared data might be updated at the same time, but no share of the data here so good) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8911c40",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'xlml'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbs4\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BeautifulSoup\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mxlml\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'xlml'"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import xlml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14a0c5c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xlml\n",
      "  Downloading XLML-0.1.2.tar.gz (2.3 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: xlml\n",
      "  Building wheel for xlml (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for xlml: filename=XLML-0.1.2-py3-none-any.whl size=2526 sha256=7424998dd83ddcff04ecb643f2e5188eb73ce22c958a173d714a5dbd3c4d19c5\n",
      "  Stored in directory: /Users/vega/Library/Caches/pip/wheels/8c/0e/d4/179755bfbbf999992498807f6b6f271650219f85bbf5270c8b\n",
      "Successfully built xlml\n",
      "Installing collected packages: xlml\n",
      "Successfully installed xlml-0.1.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ad19959",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# class getLeagueTable(object):\n",
    "    \n",
    "#     def __init__(self, leagueName):\n",
    "#         self.leagueName = leagueName\n",
    "#         self.url = \"\"\n",
    "        \n",
    "#     def getUrl(self):\n",
    "#         if self.leagueName.lower() == \"serie a\":\n",
    "#             self.url = \"https://fbref.com/en/comps/11/Serie-A-Stats\"\n",
    "#         elif self.leagueName.lower() == \"premier league\":\n",
    "#             self.url = \"https://fbref.com/en/comps/9/Premier-League-Stats\"\n",
    "#         elif self.leagueName.lower() == \"laliga\":\n",
    "#             self.url = \"https://fbref.com/en/comps/12/La-Liga-Stats\"\n",
    "#         elif self.leagueName.lower() == \"bundesliga\":\n",
    "#             self.url = \"https://fbref.com/en/comps/20/Bundesliga-Stats\"\n",
    "#         elif self.leagueName.lower() == \"league 1\":\n",
    "#             self.url = \"https://fbref.com/en/comps/13/League-1-Stats\"\n",
    "#         return self.url\n",
    "    \n",
    "#     def getTable(self):\n",
    "#         a = self.getUrl()\n",
    "#         club = requests.get(self.getUrl())\n",
    "#         # get Scores (on the same page)\n",
    "#         scores = pd.read_html(club.text)\n",
    "#         scores = pd.read_html(club.text, match = \"Regular season Table\")[0]\n",
    "#         keep = [\"Rk\", \"Squad\", \"MP\", \"W\", \"D\", \"L\", \"GF\", \"GD\", \"Pts\", \"Top Team Scorer\"]        \n",
    "#         scores = scores[keep]\n",
    "#         names = {\"Rk\": \"Rank\", \"Squad\": \"Team\", \"Pts\":\"Points\"}\n",
    "#         scores.rename(columns=names, inplace=True)  # Rename columns\n",
    "#         return scores\n",
    "\n",
    "# tb = getLeagueTable(\"Bundesliga\")\n",
    "# tb.getTable().to_html()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "808bf585",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "FeatureNotFound",
     "evalue": "Couldn't find a tree builder with the features you requested: xlml. Do you need to install a parser library?",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFeatureNotFound\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 109\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;66;03m#download the data\u001b[39;00m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;66;03m#create table object\u001b[39;00m\n\u001b[1;32m    108\u001b[0m table \u001b[38;5;241m=\u001b[39m LeagueTable()\n\u001b[0;32m--> 109\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mtable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetPLData\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetUrl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    110\u001b[0m res\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPLData.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[1], line 46\u001b[0m, in \u001b[0;36mLeagueTable.getPLData\u001b[0;34m(self, url)\u001b[0m\n\u001b[1;32m     44\u001b[0m lock \u001b[38;5;241m=\u001b[39m threading\u001b[38;5;241m.\u001b[39mLock()\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# runs only once for all clubs, returns team links\u001b[39;00m\n\u001b[0;32m---> 46\u001b[0m allClubLinks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetAllClubLinks\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m names \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComp\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCompetition\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPoss\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPossession\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSh\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShots\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSoT\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShots Target\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCrdY\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYellow\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCrdR\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRed\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFls\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFouls\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOff\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOffside\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[1;32m     49\u001b[0m result \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame()  \u001b[38;5;66;03m# Initialize an empty dataframe\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[1], line 30\u001b[0m, in \u001b[0;36mLeagueTable.getAllClubLinks\u001b[0;34m(self, url)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgetAllClubLinks\u001b[39m(\u001b[38;5;28mself\u001b[39m, url):\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;66;03m#get the response\u001b[39;00m\n\u001b[1;32m     29\u001b[0m     response \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mget(url)\n\u001b[0;32m---> 30\u001b[0m     soup \u001b[38;5;241m=\u001b[39m \u001b[43mBeautifulSoup\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mxlml\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;66;03m#select the first table and find all anchor tags\u001b[39;00m\n\u001b[1;32m     33\u001b[0m     teamTable \u001b[38;5;241m=\u001b[39m soup\u001b[38;5;241m.\u001b[39mselect(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtable.stats_table\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/mambaforge/lib/python3.10/site-packages/bs4/__init__.py:250\u001b[0m, in \u001b[0;36mBeautifulSoup.__init__\u001b[0;34m(self, markup, features, builder, parse_only, from_encoding, exclude_encodings, element_classes, **kwargs)\u001b[0m\n\u001b[1;32m    248\u001b[0m     builder_class \u001b[38;5;241m=\u001b[39m builder_registry\u001b[38;5;241m.\u001b[39mlookup(\u001b[38;5;241m*\u001b[39mfeatures)\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m builder_class \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 250\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m FeatureNotFound(\n\u001b[1;32m    251\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCouldn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt find a tree builder with the features you \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    252\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequested: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m. Do you need to install a parser library?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    253\u001b[0m             \u001b[38;5;241m%\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(features))\n\u001b[1;32m    255\u001b[0m \u001b[38;5;66;03m# At this point either we have a TreeBuilder instance in\u001b[39;00m\n\u001b[1;32m    256\u001b[0m \u001b[38;5;66;03m# builder, or we have a builder_class that we can instantiate\u001b[39;00m\n\u001b[1;32m    257\u001b[0m \u001b[38;5;66;03m# with the remaining **kwargs.\u001b[39;00m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m builder \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mFeatureNotFound\u001b[0m: Couldn't find a tree builder with the features you requested: xlml. Do you need to install a parser library?"
     ]
    }
   ],
   "source": [
    "# Create your views here.\n",
    "# from .models import myModel\n",
    "import csv\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import random\n",
    "import concurrent.futures\n",
    "import time\n",
    "import threading\n",
    "\n",
    "class LeagueTable(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.url = \"https://fbref.com/en/comps/9/Premier-League-Stats\"\n",
    "        # table = pd.DataFrame()\n",
    "\n",
    "    def getUrl(self):\n",
    "        return self.url\n",
    "    # def getTable(self):\n",
    "    #     return self.table\n",
    "    \n",
    "    # def setTable(self, df):\n",
    "    #     self.table = df\n",
    "\n",
    "    def getAllClubLinks(self, url):\n",
    "        #get the response\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.text, \"xlml\")\n",
    "        \n",
    "        #select the first table and find all anchor tags\n",
    "        teamTable = soup.select(\"table.stats_table\")[0]\n",
    "        teamLinks = teamTable.find_all(\"a\")\n",
    "        \n",
    "        #get if link has href and and \"/squads/\"\n",
    "        teamLinks = [l.get(\"href\") for l in teamLinks]\n",
    "        teamLinks = [l for l in teamLinks if \"/squads/\" in l]\n",
    "        teamLinks = [f\"https://fbref.com{l}\" for l in teamLinks]\n",
    "        print(teamLinks)\n",
    "        return teamLinks\n",
    "\n",
    "    def getPLData(self, url):\n",
    "        lock = threading.Lock()\n",
    "        # runs only once for all clubs, returns team links\n",
    "        allClubLinks = self.getAllClubLinks(url)\n",
    "        names = {\"Comp\": \"Competition\", \"Poss\": \"Possession\", \"Sh\":\"Shots\", \"SoT\":\"Shots Target\", \"CrdY\":\"Yellow\", \"CrdR\":\"Red\", \"Fls\":\"Fouls\",\"Off\":\"Offside\"}\n",
    "        \n",
    "        result = pd.DataFrame()  # Initialize an empty dataframe\n",
    "        \n",
    "        with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "            #submit each club processing as a separate task\n",
    "            club_tasks = [executor.submit(self.getClubData, link) for link in allClubLinks]\n",
    "            \n",
    "            # Process the completed tasks as they finish\n",
    "            for future in concurrent.futures.as_completed(club_tasks):\n",
    "                club_data = future.result()\n",
    "                if club_data is not None:\n",
    "                    with lock:\n",
    "                        result = pd.concat([result, club_data], axis=0, ignore_index=True)  # Concatenate current club_data with the result dataframe\n",
    "#                         print(result)\n",
    "\n",
    "        result.rename(columns=names, inplace=True)  # Rename columns\n",
    "        return result\n",
    "\n",
    "    def getAdditionalData(self, requestData, param, match, keepList):\n",
    "        soup = BeautifulSoup(requestData.text, \"xlml\")\n",
    "        all_links = soup.find_all(\"a\")\n",
    "        links = [l.get(\"href\") for l in all_links]\n",
    "        links = [l for l in links if l and param in l]\n",
    "        links = \"https://fbref.com\" + links[0]\n",
    "        time.sleep(random.randint(10,35))\n",
    "        shooting = requests.get(links)\n",
    "        shooting = pd.read_html(shooting.text, match=match)[0]\n",
    "        shooting.columns = shooting.columns.droplevel()\n",
    "        shooting = shooting[keepList]\n",
    "        return shooting[:-1]\n",
    "\n",
    "    def getClubData(self,link):\n",
    "        time.sleep(random.randint(10,35))\n",
    "        club = requests.get(link)\n",
    "        clubName = link.split(\"/\")[-1].replace(\"-Stats\",\"\").replace(\"-\", \" \")\n",
    "        print(clubName)\n",
    "\n",
    "        # get Scores (on the same page)\n",
    "        scores = pd.read_html(club.text)\n",
    "        scores = pd.read_html(club.text, match = \"Scores & Fixtures\")[0]\n",
    "        scores = scores[['Date', 'Comp', 'Day', 'Venue', 'Result', 'GF', 'GA','Opponent', 'Poss']]\n",
    "\n",
    "        # get shooting and other stat (figure better ways for these two)\n",
    "        shooting = self.getAdditionalData(club, \"/all_comps/shooting/\", \"Shooting\", ['Date', 'Sh', \"SoT\"])\n",
    "        time.sleep(random.randint(10,35))\n",
    "        misc = self.getAdditionalData(club, \"/all_comps/misc/\", \"Miscellaneous\", ['Date', 'CrdY', 'CrdR', 'Fls', 'Off'])\n",
    "        time.sleep(random.randint(10,35))\n",
    "\n",
    "    #     names = {\"Comp\": \"Competition\", \"Poss\": \"Possession\", \"Sh\":\"Shots\", \"SoT\":\"Shots Target\", \"CrdY\":\"Yellow\", \"CrdR\":\"Red\", \"Fls\":\"Fouls\",\"Off\":\"Offside\"}\n",
    "        finalClubData = scores.merge(shooting, how='left').merge(misc, how='left')\n",
    "    #     finalClubData.rename(columns=names, inplace=True)\n",
    "        finalClubData = finalClubData[finalClubData[\"Comp\"] == \"Premier League\"]\n",
    "        finalClubData[\"Team\"] = clubName\n",
    "        finalClubData['Date'] = pd.to_datetime(finalClubData['Date'])\n",
    "        finalClubData['Date'] = finalClubData['Date'].dt.strftime('%d-%b-%Y')\n",
    "#         print(clubName)\n",
    "        return finalClubData\n",
    "\n",
    "#download the data\n",
    "#create table object\n",
    "table = LeagueTable()\n",
    "res = table.getPLData(table.getUrl())\n",
    "res.to_csv(\"PLData.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
